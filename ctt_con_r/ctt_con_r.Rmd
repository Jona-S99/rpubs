---
title: "Teoría clásica de los test (CTT) - Psicometría con R"
author: "Juan Bosco Mendoza Vega"
date: "2022-09-03"
output: 
  html_document: 
    highlight: haddock
    theme: readable
    df_print: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

En este artículo revisaremos cómo realizar un análisis psicométrico usando Teoría Clásica de los Test con R. Para este análisis, se asume que tienes nociones básicas de R y psicometría.


# Una introducción informal a la Teoría Clásica de los Test
La Teoría Clásica de los Test (Classical Test Theory, CTT) es un marco de referencia usado en psicometría para analizar e interpretar los resultados de un instrumento.

La CTT es un marco de referencia con una larga historia y que se usa ampliamente en la actualidad, pero tiene limitaciones importantes para el análisis y la interpretación de resultados.

El supuesto principal de CTT es que los resultados obtenidos de un instrumento psicométrico son iguales a la medida verdadera de un rasgo o variable latente, más un error de medición.

$X = T + e$

Donde:

* $X$ = Puntaje observado.
* $T$ = Medida o puntaje verdadero de una variable o rasgo latente.
* $e$ = Error de medición.

## Supuestos
La CTT tiene tres supuestos, relacionados con el error de medición.

1. El puntaje de cada ítem no es afectado por el error, siempre que se tenga una muestra suficientemente grande. 
2. El error de un ítem o reactivo no tiene correlación con el error de un ítem distinto. 
3. El error no se correlaciona con el puntaje verdadero de una variable latente.

Se asume que el error de medida es aleatorio y que se distribuye normalmente. 

Para fines prácticos, lo anterior nos dice que mientras construyamos un instrumentos psicométricos de manera apropiada, sus resultados no deberían presentar sesgo estadístico.

Los siguientes artículos son un buen punto de partida si deseas profundizar sobre los aspectos teóricos de CTT.

* Muñiz, J. (2010). Las teorías de los tests: Teoría clásica y teoría de respuesta los ítems. *Papeles del Psicólogo, 31*(1), 57-66
https://dibujo.uniovi.es/dspace/bitstream/handle/10651/10994/?sequence=1 
* Hambleton, R. K., & Jones, R. W. (1993). Comparison of classical test theory and item response theory and their applications to test development. *Educational measurement: issues and practice, 12*(3), 38-47.
https://www.sciencedirect.com/science/article/pii/S0149291814002045 

## Ventajas
Las principales ventajas de la CTT es que podemos hacer estimación de sus indicadores psicométricos con una muestra relativamente pequeña y que estos resultados son fáciles de calcular e interpretar.

Esto último suele ser útil para comunicar resultados a un público no especialista a diferencia de la Teoría de Respuesta al Ítem (IRT) que requiere de mayor familiaridad con conceptos de probabilidad y psicometría.

## Limitaciones
Este marco de referencia tiene las siguientes limitaciones.

* Se enfoca en el instrumento, no en los reactivos. El instrumento es la unidad de análisis, si el instrumento se modifica de cualquier manera, es necesario realizar de nuevo el análisis e interpretación de resultados.
* Los puntajes de los ítems dependen de la muestra, por lo tanto, el puntaje de los instrumentos también lo hará. En consecuencia, los indicadores psicométricos de un instrumento y las personas que lo han contestado son inseparables.
* Existe una medida de confiabilidad única para todo un instrumento, todos los reactivos y todos los respondentes. No podemos obtener la confiabilidad de un reactivo en particular

Para facilitar la lectura, en adelante usaremos de manera indistinta "ítem" y "reactivo", además de que nos referiremos a respuestas "correctas" e "incorrectas" al hablar de respuestas que indican la presencia o ausencia de un rasgo latente, respectivamente.

# CTT con R
R cuenta con el paquete `CTT` que nos facilita realizar los análisis relacionados con este marco de referencia de manera sencilla.

Instalamos este paquetes con la función `install.packages()`.

```{r instalar_paquete, eval=FALSE}
install.packages("CTT")
```

Cargamos estos paquetes a nuestro entorno de trabajo con la función `library()`.

```{r cargar_paquetes, warning=FALSE, message=FALSE}
library(CTT)
```

# Lectura y procesamiento de datos

Usaremos un subconjunto de datos de una evaluación nacional de aprendizaje de matemáticas, realizada en 2018 a estudiantes de sexto de primaria de México.

Puedes descargar estos datos de la siguiente liga:

* https://raw.githubusercontent.com/jboscomendoza/rpubs/master/ctt_con_r/data_mat.csv

Puedes encontrar los datos originales en la siguiente liga.

* https://www.inee.edu.mx/evaluaciones/planea/sexto-primaria-ciclo-2017-2018/

## Lectura de datos
Leemos los datos usando `read.csv()`. El resultado será un data frame que asignamos a la variable `matematicas`.

```{r leer_csv, warning=FALSE, message=FALSE}
matematicas <- read.csv("data_mat.csv")
```

Damos una vistazo a los datos con `summary()`.

```{r}
summary(matematicas)
```

Podemos observar que todos los datos tienen valores entre 0 y 1. 

Si usamos `table`, comprobamos que tenemos datos binarios en cada columna de nuestro data frame.

```{r}
sapply(matematicas, table, useNA = "ifany")
```


Para nuestro análisis, cada renglón del data frame debe representar a una persona y cada columna un ítem o reactivo al que han contestado, es decir,  cada renglón es un patrón de respuesta.

Nuestros datos también deben estar codificados de modo que las respuestas correctas latente sean igual a `1`, mientras que las respuestas incorrectas o que indican la ausencia de un rasgo, sean igual a `0`.

Los datos que hemos leído cumplen con estas condiciones, pero veamos el caso para datos que esto no ocurre.


## Recodificando a 0 y 1 con la función score()

Es común que al procesar datos de pruebas psicométricas, en particular de exámenes, nuestros datos requieran recodificarse.

El paquete `CTT` cuenta con la función `score()` que nos permite recodificar nuestros datos si contamos con una clave de respuesta. Además, en el proceso obtenemos los puntajes totales de todas las personas, es decir, el número total de respuestas correctas que han obtenido.

La clave de respuesta es una vector de texto que, para cada columna, contiene valores correspondientes a la respuesta correcta. 

Por ejemplo, si nuestros datos tienen cinco columnas, la cadena de texto debe tener un largo de cinco elementos.

```{r ejemplo_clave, eval=FALSE}
c("A", "C", "D", "B", "A")
```

De esta manera, para la columna 1, todos los valores iguales a "A" serán recodificados como `1` y los demás como `0`; para la columna 2, todos los valores iguales a "C" serán recodificados como `1` y los demás como `0`; y así sucesivamente.

Usaremos un conjunto de datos que no se encuentra recodificado. Es un extracto de los datos que hemos leído anteriormente, pero sin codificar.

Puedes descargar estos datos del siguiente enlace:

* https://raw.githubusercontent.com/jboscomendoza/rpubs/master/ctt_con_r/data_mat_nc.csv

Leemos los datos con la función `read.csv()` y los asignaremos a la variable `mate_nc`.

```{r lectura_nocodificados}
mate_nc <- read.csv("data_mat_nc.csv")
```

Demos un vistazo a estos datos con `head()`.

```{r head_nc}
head(mate_nc)
```

Como ya lo mencionamos, para recodificar necesitamos una clave de respuestas. Vamos a asignar una a la variable `clave_respuesta`.

```{r clave_respuesta}
clave_respuesta <- c("A", "C", "D", "B", "A")
```

Finalmente, usamos la función `score()` de CTT. Damos como argumento adicional `output.scores = TRUE` para obtener una copia de nuestros datos ya recodificados.

```{r mate_recoded}
mate_recoded <- score(items = mate_nc, key = clave_respuesta, output.scored = TRUE)
```

Veamos nuestro resultado.

```{r mate_recoded_ver}
mate_recoded
```

Si lo deseamos podemos usar nuestros datos recodificados más adelante llamándolos con `mate_recoded`scores`.

Veamos ahora el caso con datos ya codificados.

## Usando score() con datos codificados

Si nuestros datos ya se encuentran codificados como `0` igual a "incorrecto" y `1` igual a "correcto", podemos usar la función `score()` de `CTT` para obtener los puntajes de cada persona.

En este caso, dando como único argumento a `score()` nuestro data frame `matematicas` y asignamos los resultados a la variable `matematicas_score`.

```{r matematicas_score}
matematicas_score <- score(matematicas)
```

Al llamar la función de esta manera, se nos muestra un mensaje, informando que se ha asumido que los datos se encuentran sido codificados ("No key provided, assuming pre-scored data.")

Veamos las primeras diez entradas de nuestros resultados.
```{r}
matematicas_score$score[1:10]
```

Nuevamente, el resultado corresponde a la suma de los valores iguales a `1` de cada persona. No es un procedimiento particularmente complejo, en realidad podríamos replicar este proceso con la función `rowSums()` de R base.

```{r}
matematicas_score_rowsums <- rowSums(matematicas)

matematicas_score_rowsums[1:10]
```


Si lo deseamos, podemos crear una gráfica de los resultados con la función `hist()`.


```{r}
hist(matematicas_score$score)
```

Naturalmente, también podemos obtener otros estadísticos útiles, como los cuantiles de los puntajes.

```{r}
quantile(matematicas_score$score)
```

Los resultados más complejos de CTT los obtenemos con la función `itemAnalysis()`.

# Análisis de reactivos con `itemAnalysis()`

La función `itemAnalysis()` no devuelve un análisis de las principales propiedades psicométricas de los reactivos en nuestro conjunto de datos.

Esta función nos pide como argumentos los patrones de respuesta codificados a `0` y `1` en un data frame. También podemos definir argumentos adicionales que cambian la manera en que nos son devueltos los resultados.

En este caso, proporcionamos el argumento `hardFlag = 0.25`, para que sean marcados los reactivos con un valor de dificultad menor o igual a `0.25`; y el argumento `pBisFlag = 0.3`, para que sean marcados los reactivos con una discriminación menor o igual a `0.3`. 

Veremos la interpretación de estos valores un poco más adelante.

Ejecutamos nuestro código con estos parámetros y asignamos el resultado a la variable `matematicas_ctt`.

```{r itemanalysis}
matematicas_ctt <- itemAnalysis(items = matematicas, hardFlag=.25, pBisFlag=.3)
```

Si llamamos a la variable **matematicas_ctt** se nos muestra el resumen del análisis.

```{r}
matematicas_ctt
```

Comprobamos que este resumen corresponde con nuestros datos, 25 reactivo y respuestas de 450 personas. También hemos obtenido un valor de Alpha de Cronbach igual a `0.836`. En la siguiente sección veremos cómo interpretar este y los demás resultados obtenidos.

## Reporte e interpretación de resultados

Para obtener un análisis detallado de nuestros reactivos, llamamos al elemento `itemReport` de la variable **matematicas_ctt**.

```{r}
matematicas_ctt$itemReport
```

Veamos cómo interpretar cada parte de este reporte.

### itemName
El nombre del reactivo, corresponde al nombre de la columna del data frame con nuestros datos.

### itemMean
La dificultad del reactivo, expresada como proporción de respuesta correcta o presencia del rasgo. Es decir, un reactivo con valores cercanos a `0` es más "difícil", pues menos personas han contestado correctamente o elegido una respuesta que indica presencia de un rasgo. 

Si, por el contrario, los valores se encuentran cercanos a `1`, un reactivo es más "fácil", pues más personas lo han contestado correctamente o eligiendo una respuesta que indica presencia del rasgo. Naturalmente, podemos convertir estos valores a porcentaje multiplicándolos por `100`.

Si lo deseamos, podemos graficar las dificultades con `hist()`.

```{r dificultad_hist}
hist(matematicas_ctt$itemReport$itemMean)
```

En algunos casos es más fácil interpretar la dificultad si valores más cercanos a `1` indican reactivos más difíciles y cercanos a 0, reactivos más fáciles. 

Podemos obtener estos valores, restamos las dificultades que hemos obtenido a 1.

```{r}
1 - matematicas_ctt$itemReport$itemMean
```

### pBis
Correlación punto biserial (pBis). Es una medida de **discriminación**, que indica la correlación entre las respuesta a un reactivo en particular y el puntaje total de cada persona, es decir, entre una variable binaria y una variable continua.

Valores cercanos a `1` indican una asociación positiva o directa entre respuesta correctas o que indican la presencia de un rasgo con puntajes totales altos. Si este valor sea negativo, cercano a `-1`, una respuesta correcta o que indica presencia del rasgo es observada al mismo tiempo que un puntaje total bajo.

De manera conceptual, un reactivo con una discriminación alta y positiva, es más probable que sea contestado correctamente por una persona que tiene alta magnitud del rasgo medido, que observamos a partir de un puntaje total alto.

Reactivos con discriminación negativa indican un comportamiento inverso, es más probable que sean contestados correctamente por personas con una baja presencia del rasgo medido. Si esto ocurre, es necesaria una revisión del reactivo y es candidato para ser eliminado del instrumento.

Consideramos `0.30` como un valor aceptable de pBis.

### bis
Correlación biserial. También es un indicador de discriminación y tiende a devolver valores más altos que punto biserial. En realidad, esta correlación asume que ambas variables comparadas son binarias, de allí que se obtengan resultados distintos.

`0.30` es también un valor aceptable, pero es más fácil alcanzarlo con esta correlación.

### alphaIfDeleted
Es el valor que tendrá el coeficiente Alfa de Cronbach si un reactivo en particular es eliminado.

El coeficiente Alfa de Cronbach es un indicador de consistencia interna o confiabilidad de un instrumento psicométrico y puede asumir valores entre `0` y `1`. Si obtenemos valores altos, cercanos a 1, asumimos que todos nuestros reactivos tiene cierta homogeneidad en lo que están midiendo, decimos que están "apuntando" en la misma dirección. 

Esta última analogía en realidad es más literal de lo que parece, pues obtenemos este coeficiente a partir de las covarianza (intercorrelaciones, expresadas en una matriz) de nuestros reactivos.

Para fines prácticos, basta saber que valores de Alfa iguales o mayores a `0.80` son considerados buenos.

En nuestro caso, hemos obtenido un valor de `0.836` y hay al menos un reactivo que podemos eliminar de nuestro análisis e incrementarán este valor (PMA_1). Los reactivos que aumentan el valor de Alfa al teóricamente están midiendo algo diferente a los demás, por lo tanto, también deben revisarse.


# Análisis de distractores con distractorAnalysis()
Finalmente, podemos realizar un análisis de distractores usando la función `distractorAnalysis()`.

Este análisis se usa en exámenes de aprendizaje y consiste en comparar la proporción con la que han sido elegidos los distractores (las respuestas incorrectas) con respecto a la respuesta correcta. También se puede analizar qué grupos de desempeño de las personas que han contestado un examen, en función del puntaje que han obtenido en este, eligen más o menos un distractor específico.,

Por ejemplo, podemos encontrar que para un reactivo en particular, un distractor (respuesta incorrecta) ha sido elegido en su mayoría por las personas con los puntajes más altos. Esto quiere decir que las personas que demuestran mayor aprendizaje eligen una opción de respuesta incorrecta como plausible, por lo tanto debemos revisar porqué ocurre esto.

En ocasiones, observamos que un distractor está siendo elegido por las personas con desempeño más alto y la explicación se encuentra en el procesamiento de los datos. Por ejemplo, ha etiquetado de manera equivocada una respuesta correcta como si fuera incorrecta, o nuestra clave de respuesta contiene errores.

Para realizar el análisis de distractores necesitamos los patrones de respuesta originales, antes de codificarse a `0` y `1`. Usaremos un conjunto de datos y clave de respuesta incluidas con el paquete `CTT`.

```{r data_ctt}
data(CTTdata)
data(CTTkey)
```

La función `distractorAnalysis()` nos pide dos argumentos, un data frame con los patrones de respuesta y una clave de respuesta. Usaremos los conjuntos de datos `CTTdata` y `CTTkey`, y asignamos los resultados a la variable `distractores`.

```{r distractores_analisis}
distractores <- distractorAnalysis(CTTdata, CTTkey)
```

El resultado es una lista que contiene el análisis de distractores para cada reactivo en nuestro conjunto de datos. 

Veamos el análisis para el primer reactivos.

```{r distractores_primer_reactivo}
distractores[[1]]
```

La interpretación de los resultados se hace por opción de respuesta.

### correct
Marca con un asterisco (`*`) la opción de respuesta correcta, de acuerdo con la clave de respuesta que hemos proporcionado. En este caso **D**.

### key
El valor que corresponde a la opción de respuesta en nuestro conjunto de datos.

### n y rspP
Cantidad de personas y proporción de personas que han elegido una opción en particular, respectivamente. Para este reactivo, la opción correcta fue elegida por 47 personas, una proporción de `0.47`.

### pBis
Correlación punto biserial. Un indicador de discriminación que hemos revisado en este mismo documento. Para la respuesta correcta el valor es `0.53`, que se considera bueno. Las opciones incorrectas deben tener valores negativos, pues esto indica que han sido elegidas principalmente por personas con bajo nivel de desempeño.

### discrim
Un indicador de discriminación. Corresponde a la diferencia entre la proporción de personas en el nivel más alto de desempeño que han elegido la opción de respuesta, menos la proporción de personas en el nivel de desempeño más bajo que también la han elegido. Estos valores se encuentran en las columnas `lower` y `upper`.

Entre más cercano sea este valor a `1`, mejor discrimina la opción de respuesta. Al igual que con la correlación punto biserial, las opciones de respuesta incorrecta deben tener discriminación negativa.

Para la respuesta correcta, el valor es `0.81` (`0.94736842 - 0.1333333`), lo cual es bueno.

### lower, mid50, mid75, upper
Cada columna nos indica la proporción en la que cada grupo de desempeño ha elegido cada opción de respuesta.

Cada grupo corresponde con un puntaje obtenido a todo el instrumento, en decir, su porcentaje de respuestas corrrectas.

* lower: 0 a 25% (Grupo de desempeño más bajo.)
* mid50: 26 a 50%
* mid75: 51 a 75%
* upper: 76 a 100% (Grupo de desempeño más alto.)

Lo que deseamos es tener opciones correctas que han sido elegidas en su mayoría por el grupo de desempeño más alto y el grupo de desempeño más bajo es el que menos la ha seleccionado. Idealmente, los grupos de desempeño eligen gradualmente en mayor proporción la respuesta correcta y, de manera inversa, menos veces las opciones de respuesta incorrectas.

En este caso, el `94.7%` del grupo de desempeño más alto eligió la respuesta correcta, mientras que el sólo la eligió el `13.3%` del grupo de desempeño más bajo. Por esta razón, si en la columna `discrim` obtenemos un valor de `1`, podemos decir que tenemos una opción de respuesta con discriminación perfecta.


# Para concluir
La Teoría Clásica de los Test (CTT), aunque tiene limitaciones importantes, es un marco de referencia sumamente útil en psicometría y el paquete `CTT` de R nos permite ponerla en práctica.

Si además de obtener puntajes globales y dificultad de los reactivos aprovechamos los distintos indicadores estadísticos que están asociados a este marco de referencia, podremos entender mejor el funcionamiento de un instrumento psicométrico, lo cual no sólo se limita a exámenes de aprendizaje.

Si tenemos datos suficientes y el diseño de nuestros instrumentos nos los permiten, es deseable complementar los resultados obtenidos con CTT con los obtenidos usando Teoría de Respuesta al Ítem (IRT).

Aunque IRT tiene muchas bondades, en la práctica nuestros datos pueden ser inadecuados para aplicar esta teoría, por lo que resulta muy valioso tener fundamentos sólidos de CTT.

----

Consultas, dudas, comentarios y correcciones son bienvenidas:

* jboscomendoza@gmail.com

El código y los datos usados en este documento se encuentran en Github:

* https://github.com/jboscomendoza/rpubs/tree/master/ctt_con_r 